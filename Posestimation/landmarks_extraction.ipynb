{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_names = [\n",
    "        \"WRIST\",\n",
    "        \"THUMB_CMC\", \"THUMB_MCP\", \"THUMB_IP\", \"THUMB_TIP\",\n",
    "        \"INDEX_FINGER_MCP\", \"INDEX_FINGER_PIP\", \"INDEX_FINGER_DIP\", \"INDEX_FINGER_TIP\",\n",
    "        \"MIDDLE_FINGER_MCP\", \"MIDDLE_FINGER_PIP\", \"MIDDLE_FINGER_DIP\", \"MIDDLE_FINGER_TIP\",\n",
    "        \"RING_FINGER_MCP\", \"RING_FINGER_PIP\", \"RING_FINGER_DIP\", \"RING_FINGER_TIP\",\n",
    "        \"PINKY_MCP\", \"PINKY_PIP\", \"PINKY_DIP\", \"PINKY_TIP\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path =\"/home/ruwantha/Repos/sign-project/SignLanguageTutor/Data/SinhalaData/ImageSet/Sinhala Images/à¶… - 06\"\n",
    "output_csv_path = \"/home/ruwantha/Repos/sign-project/SignLanguageTutor/Data/SinhalaData/CSV/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hand model\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733024504.514909   63808 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1733024504.517028   69931 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.7-arch1.1), renderer: Mesa Intel(R) UHD Graphics 620 (KBL GT2)\n",
      "W0000 00:00:1733024504.532342   69923 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733024504.546269   69922 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handedness for 2.jpg: Left\n",
      "Handedness for 21.jpg: Left\n",
      "Handedness for 45.jpg: Left\n",
      "Handedness for 44.jpg: Left\n",
      "Handedness for 20.jpg: Left\n",
      "Handedness for 1.jpg: Left\n",
      "Landmark data saved to /home/ruwantha/Repos/sign-project/SignLanguageTutor/Data/SinhalaData/CSV/test.csv\n"
     ]
    }
   ],
   "source": [
    "# Create or overwrite the CSV file and write the header\n",
    "with open(output_csv_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write header with columns for each landmark's coordinates for both hands\n",
    "    header = [\"Image\"]\n",
    "    for hand in [\"Left\", \"Right\"]:\n",
    "        for landmark_name in landmark_names:\n",
    "            header.extend([f\"{hand}_{landmark_name}_X\", f\"{hand}_{landmark_name}_Y\", f\"{hand}_{landmark_name}_Z\"])\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Initialize the Hand model\n",
    "    with mp_hands.Hands(\n",
    "            static_image_mode=True,  # Set to static mode for images\n",
    "            max_num_hands=2,  # Detect up to 2 hands\n",
    "            min_detection_confidence=0.5  # Detection threshold\n",
    "    ) as hands:\n",
    "        # Loop through all files in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            # Check if file is an image (e.g., .jpg, .jpeg, .png)\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Convert the image to RGB for MediaPipe processing\n",
    "                rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Process the image and detect hands\n",
    "                result = hands.process(rgb_image)\n",
    "\n",
    "                # Initialize row data with the filename\n",
    "                row_data = [filename]\n",
    "\n",
    "                # Prepare placeholders for left and right hand landmarks\n",
    "                left_hand_data = [0.0] * (len(landmark_names) * 3)\n",
    "                right_hand_data = [0.0] * (len(landmark_names) * 3)\n",
    "\n",
    "                if result.multi_hand_landmarks and result.multi_handedness:\n",
    "                    for hand_idx, (hand_landmarks, handedness) in enumerate(\n",
    "                            zip(result.multi_hand_landmarks, result.multi_handedness)):\n",
    "                        # Identify the hand as \"Left\" or \"Right\"\n",
    "                        hand_label = handedness.classification[0].label\n",
    "                        print(f\"Handedness for {filename}: {handedness.classification[0].label}\")\n",
    "\n",
    "\n",
    "                        # Prepare data list for the detected hand\n",
    "                        hand_data = []\n",
    "\n",
    "                        # Get wrist coordinates for normalization\n",
    "                        wrist = hand_landmarks.landmark[0]\n",
    "                        wrist_x, wrist_y, wrist_z = wrist.x, wrist.y, wrist.z\n",
    "\n",
    "                        # Add normalized landmark data for each landmark\n",
    "                        for landmark in hand_landmarks.landmark:\n",
    "                            norm_x = round(landmark.x - wrist_x,2)\n",
    "                            norm_y = round(landmark.y - wrist_y,2)\n",
    "                            norm_z = round(landmark.z - wrist_z,2)\n",
    "                            hand_data.extend([norm_x, norm_y, norm_z])\n",
    "\n",
    "                        # Assign data to left or right hand list based on label\n",
    "                        if hand_label == \"Left\":\n",
    "                            left_hand_data = hand_data\n",
    "                        elif hand_label == \"Right\":\n",
    "                            right_hand_data = hand_data\n",
    "\n",
    "                # Append left and right hand data to the row data\n",
    "                row_data.extend(left_hand_data)\n",
    "                row_data.extend(right_hand_data)\n",
    "\n",
    "                # Write data for this image to the CSV file\n",
    "                csv_writer.writerow(row_data)\n",
    "\n",
    "print(f\"Landmark data saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733024982.705546   70711 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1733024982.709369   70944 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.7-arch1.1), renderer: Mesa Intel(R) UHD Graphics 620 (KBL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733024982.734094   70935 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733024982.761164   70936 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733024982.839755   70934 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right hand landmark data saved to /home/ruwantha/Repos/sign-project/SignLanguageTutor/Data/SinhalaData/CSV/test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "\n",
    "\n",
    "landmark_names = [  # Define landmark names\n",
    "    \"WRIST\", \"THUMB_CMC\", \"THUMB_MCP\", \"THUMB_IP\", \"THUMB_TIP\",\n",
    "    \"INDEX_FINGER_MCP\", \"INDEX_FINGER_PIP\", \"INDEX_FINGER_DIP\", \"INDEX_FINGER_TIP\",\n",
    "    \"MIDDLE_FINGER_MCP\", \"MIDDLE_FINGER_PIP\", \"MIDDLE_FINGER_DIP\", \"MIDDLE_FINGER_TIP\",\n",
    "    \"RING_FINGER_MCP\", \"RING_FINGER_PIP\", \"RING_FINGER_DIP\", \"RING_FINGER_TIP\",\n",
    "    \"PINKY_MCP\", \"PINKY_PIP\", \"PINKY_DIP\", \"PINKY_TIP\"\n",
    "]\n",
    "\n",
    "# Create or overwrite the CSV file and write the header\n",
    "with open(output_csv_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write header with columns for the right hand landmarks\n",
    "    header = [\"Image\"]\n",
    "    for landmark_name in landmark_names:\n",
    "        header.extend([f\"Right_{landmark_name}_X\", f\"Right_{landmark_name}_Y\", f\"Right_{landmark_name}_Z\"])\n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Initialize the Hand model\n",
    "    with mp.solutions.hands.Hands(\n",
    "            static_image_mode=True,  # Static mode for images\n",
    "            max_num_hands=2,  # Detect up to 2 hands\n",
    "            min_detection_confidence=0.5  # Detection threshold\n",
    "    ) as hands:\n",
    "        # Loop through all files in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            # Check if file is an image (e.g., .jpg, .jpeg, .png)\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Convert the image to RGB for MediaPipe processing\n",
    "                rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Process the image and detect hands\n",
    "                result = hands.process(rgb_image)\n",
    "\n",
    "                # Initialize row data with the filename\n",
    "                row_data = [filename]\n",
    "\n",
    "                # Prepare placeholder for right-hand landmarks\n",
    "                right_hand_data = [0.0] * (len(landmark_names) * 3)\n",
    "\n",
    "                if result.multi_hand_landmarks and result.multi_handedness:\n",
    "                    for hand_landmarks, handedness in zip(result.multi_hand_landmarks, result.multi_handedness):\n",
    "                        # Identify the hand as \"Right\"\n",
    "                        hand_label = handedness.classification[0].label\n",
    "                        if hand_label == \"Right\":\n",
    "                            print(f\"Right hand detected for {filename}\")\n",
    "\n",
    "                            # Prepare data list for the detected right hand\n",
    "                            hand_data = []\n",
    "\n",
    "                            # Get wrist coordinates for normalization\n",
    "                            wrist = hand_landmarks.landmark[0]\n",
    "                            wrist_x, wrist_y, wrist_z = wrist.x, wrist.y, wrist.z\n",
    "\n",
    "                            # Add normalized landmark data for each landmark\n",
    "                            for landmark in hand_landmarks.landmark:\n",
    "                                norm_x = round(landmark.x - wrist_x, 2)\n",
    "                                norm_y = round(landmark.y - wrist_y, 2)\n",
    "                                norm_z = round(landmark.z - wrist_z, 2)\n",
    "                                hand_data.extend([norm_x, norm_y, norm_z])\n",
    "\n",
    "                            # Assign data to right-hand list\n",
    "                            right_hand_data = hand_data\n",
    "                            break  # Stop processing other hands since we're only interested in the right hand\n",
    "\n",
    "                # Append right-hand data to the row data\n",
    "                row_data.extend(right_hand_data)\n",
    "\n",
    "                # Write data for this image to the CSV file\n",
    "                csv_writer.writerow(row_data)\n",
    "\n",
    "print(f\"Right hand landmark data saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
